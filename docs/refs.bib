@ARTICLE{Arden2017-as,
  title    = "{Detection of Toscana virus from an adult traveler returning to
              Australia with encephalitis}",
  author   = "Arden, Katherine E and Heney, Claire and Shaban, Babak and Nimmo,
              Graeme R and Nissen, Michael D and Sloots, Theo P and Mackay, Ian
              M",
  abstract = "Toscana virus (TOSV) is identified in sandflies, animals, and
              humans around the Mediterranean Sea. TOSV has not been reported
              in Australia. During investigations of cerebrospinal fluid
              samples from patients with encephalitis, TOSV genetic sequences
              were identified in a traveler returning to Australia from Europe.
              TOSV should be considered, especially during May to October, in
              travelers to Australia who embarked in countries in and around
              the Mediterranean Sea and who subsequently present for medical
              care because of neurological symptoms.",
  journal  = "J. Med. Virol.",
  volume   =  89,
  number   =  10,
  pages    = "1861--1864",
  month    =  oct,
  year     =  2017,
  keywords = "Phlebovirus; Toscana virus; encephalitis; high throughput
              sequencing; travel",
  language = "en"
}
@ARTICLE{Roediger2018-lq,
  title     = "{An atypical Parvovirus drives chronic tubulointerstitial
               nephropathy and kidney fibrosis}",
  author    = "Roediger, Ben and Lee, Quintin and Tikoo, Shweta and Cobbin,
               Joanna C A and Henderson, James M and Jormakka, Mika and
               O'Rourke, Matthew B and Padula, Matthew P and Pinello, Natalia
               and Henry, Marisa and Wynne, Maria and Santagostino, Sara F and
               Brayton, Cory F and Rasmussen, Lorna and Lisowski, Leszek and
               Tay, Szun S and Harris, David C and Bertram, John F and Dowling,
               John P and Bertolino, Patrick and Lai, Jack H and Wu, Wengen and
               Bachovchin, William W and Wong, Justin J-L and Gorrell, Mark D
               and Shaban, Babak and Holmes, Edward C and Jolly, Christopher J
               and Monette, S{\'e}bastien and Weninger, Wolfgang",
  abstract  = "The occurrence of a spontaneous nephropathy with intranuclear
               inclusions in laboratory mice has puzzled pathologists for over
               4 decades, because its etiology remains elusive. The condition
               is more severe in immunodeficient animals, suggesting an
               infectious cause. Using metagenomics, we identify the causative
               agent as an atypical virus, termed ``mouse kidney parvovirus''
               (MKPV), belonging to a divergent genus of Parvoviridae. MKPV was
               identified in animal facilities in Australia and North America,
               is transmitted via a fecal-oral or urinary-oral route, and is
               controlled by the adaptive immune system. Detailed analysis of
               the clinical course and histopathological features demonstrated
               a stepwise progression of pathology ranging from sporadic
               tubular inclusions to tubular degeneration and interstitial
               fibrosis and culminating in renal failure. In summary, we
               identify a widely distributed pathogen in laboratory mice and
               establish MKPV-induced nephropathy as a new tool for elucidating
               mechanisms of tubulointerstitial fibrosis that shares molecular
               features with chronic kidney disease in humans.",
  journal   = "Cell",
  publisher = "Elsevier BV",
  volume    =  175,
  number    =  2,
  pages     = "530--543.e24",
  month     =  oct,
  year      =  2018,
  keywords  = "Parvoviridae; chronic kidney disease; fibrosis; inclusion body
               nephropathy; parvovirus; tubulointerstitial fibrosis; viral
               metagenomics",
  copyright = "http://www.elsevier.com/open-access/userlicense/1.0/",
  language  = "en"
}
@misc{Andrews:2010tn,
  added-at = {2012-06-02T05:59:56.000+0200},
  author = {Andrews, S.},
  biburl = {https://www.bibsonomy.org/bibtex/2b6052877491828ab53d3449be9b293b3/ozborn},
  date-added = {2012-06-01 16:59:33 -0500},
  date-modified = {2012-06-01 16:59:49 -0500},
  interhash = {f230a919c34360709aa298734d63dca3},
  intrahash = {b6052877491828ab53d3449be9b293b3},
  keywords = {imported},
  timestamp = {2012-06-03T07:20:30.000+0200},
  title = {{FASTQC. A quality control tool for high throughput sequence data}},
  year = 2010
}
@ARTICLE{Magoc2011-gb,
  title     = "{FLASH}: fast length adjustment of short reads to improve genome
               assemblies",
  author    = "Mago{\v c}, Tanja and Salzberg, Steven L",
  abstract  = "MOTIVATION: Next-generation sequencing technologies generate
               very large numbers of short reads. Even with very deep genome
               coverage, short read lengths cause problems in de novo
               assemblies. The use of paired-end libraries with a fragment size
               shorter than twice the read length provides an opportunity to
               generate much longer reads by overlapping and merging read pairs
               before assembling a genome. RESULTS: We present FLASH, a fast
               computational tool to extend the length of short reads by
               overlapping paired-end reads from fragment libraries that are
               sufficiently short. We tested the correctness of the tool on one
               million simulated read pairs, and we then applied it as a
               pre-processor for genome assemblies of Illumina reads from the
               bacterium Staphylococcus aureus and human chromosome 14. FLASH
               correctly extended and merged reads >99\% of the time on
               simulated reads with an error rate of <1\%. With adequately set
               parameters, FLASH correctly merged reads over 90\% of the time
               even when the reads contained up to 5\% errors. When FLASH was
               used to extend reads prior to assembly, the resulting assemblies
               had substantially greater N50 lengths for both contigs and
               scaffolds. AVAILABILITY AND IMPLEMENTATION: The FLASH system is
               implemented in C and is freely available as open-source code at
               http://www.cbcb.umd.edu/software/flash. CONTACT:
               t.magoc@gmail.com.",
  journal   = "Bioinformatics",
  publisher = "Oxford University Press (OUP)",
  volume    =  27,
  number    =  21,
  pages     = "2957--2963",
  month     =  nov,
  year      =  2011,
  language  = "en"
}

@ARTICLE{Schmieder2011-jr,
  title     = "Fast identification and removal of sequence contamination from
               genomic and metagenomic datasets",
  author    = "Schmieder, Robert and Edwards, Robert",
  abstract  = "High-throughput sequencing technologies have strongly impacted
               microbiology, providing a rapid and cost-effective way of
               generating draft genomes and exploring microbial diversity.
               However, sequences obtained from impure nucleic acid
               preparations may contain DNA from sources other than the sample.
               Those sequence contaminations are a serious concern to the
               quality of the data used for downstream analysis, causing
               misassembly of sequence contigs and erroneous conclusions.
               Therefore, the removal of sequence contaminants is a necessary
               and required step for all sequencing projects. We developed
               DeconSeq, a robust framework for the rapid, automated
               identification and removal of sequence contamination in
               longer-read datasets (150 bp mean read length). DeconSeq is
               publicly available as standalone and web-based versions. The
               results can be exported for subsequent analysis, and the
               databases used for the web-based version are automatically
               updated on a regular basis. DeconSeq categorizes possible
               contamination sequences, eliminates redundant hits with higher
               similarity to non-contaminant genomes, and provides graphical
               visualizations of the alignment results and classifications.
               Using DeconSeq, we conducted an analysis of possible human DNA
               contamination in 202 previously published microbial and viral
               metagenomes and found possible contamination in 145 (72\%)
               metagenomes with as high as 64\% contaminating sequences. This
               new framework allows scientists to automatically detect and
               efficiently remove unwanted sequence contamination from their
               datasets while eliminating critical limitations of current
               methods. DeconSeq's web interface is simple and user-friendly.
               The standalone version allows offline analysis and integration
               into existing data processing pipelines. DeconSeq's results
               reveal whether the sequencing experiment has succeeded, whether
               the correct sample was sequenced, and whether the sample
               contains any sequence contamination from DNA preparation or
               host. In addition, the analysis of 202 metagenomes demonstrated
               significant contamination of the non-human associated
               metagenomes, suggesting that this method is appropriate for
               screening all metagenomes. DeconSeq is available at
               http://deconseq.sourceforge.net/.",
  journal   = "PLoS One",
  publisher = "Public Library of Science (PLoS)",
  volume    =  6,
  number    =  3,
  pages     = "e17288",
  month     =  mar,
  year      =  2011,
  language  = "en"
}
@ARTICLE{Hyatt2010-zh,
  title     = "Prodigal: prokaryotic gene recognition and translation
               initiation site identification",
  author    = "Hyatt, Doug and Chen, Gwo-Liang and Locascio, Philip F and Land,
               Miriam L and Larimer, Frank W and Hauser, Loren J",
  abstract  = "BACKGROUND: The quality of automated gene prediction in
               microbial organisms has improved steadily over the past decade,
               but there is still room for improvement. Increasing the number
               of correct identifications, both of genes and of the translation
               initiation sites for each gene, and reducing the overall number
               of false positives, are all desirable goals. RESULTS: With our
               years of experience in manually curating genomes for the Joint
               Genome Institute, we developed a new gene prediction algorithm
               called Prodigal (PROkaryotic DYnamic programming Gene-finding
               ALgorithm). With Prodigal, we focused specifically on the three
               goals of improved gene structure prediction, improved
               translation initiation site recognition, and reduced false
               positives. We compared the results of Prodigal to existing
               gene-finding methods to demonstrate that it met each of these
               objectives. CONCLUSION: We built a fast, lightweight, open
               source gene prediction program called Prodigal
               http://compbio.ornl.gov/prodigal/. Prodigal achieved good
               results compared to existing methods, and we believe it will be
               a valuable asset to automated microbial annotation pipelines.",
  journal   = "BMC Bioinformatics",
  publisher = "Springer Nature",
  volume    =  11,
  number    =  1,
  pages     = "119",
  month     =  mar,
  year      =  2010,
  language  = "en"
}
@ARTICLE{Buchfink2015-rn,
  title     = "Fast and sensitive protein alignment using {DIAMOND}",
  author    = "Buchfink, Benjamin and Xie, Chao and Huson, Daniel H",
  abstract  = "The alignment of sequencing reads against a protein reference
               database is a major computational bottleneck in metagenomics and
               data-intensive evolutionary projects. Although recent tools
               offer improved performance over the gold standard BLASTX, they
               exhibit only a modest speedup or low sensitivity. We introduce
               DIAMOND, an open-source algorithm based on double indexing that
               is 20,000 times faster than BLASTX on short reads and has a
               similar degree of sensitivity.",
  journal   = "Nat. Methods",
  publisher = "Springer Science and Business Media LLC",
  volume    =  12,
  number    =  1,
  pages     = "59--60",
  month     =  jan,
  year      =  2015,
  language  = "en"
}
@ARTICLE{Li2010-nl,
  title     = "Fast and accurate long-read alignment with {Burrows-Wheeler}
               transform",
  author    = "Li, Heng and Durbin, Richard",
  abstract  = "MOTIVATION: Many programs for aligning short sequencing reads to
               a reference genome have been developed in the last 2 years. Most
               of them are very efficient for short reads but inefficient or
               not applicable for reads >200 bp because the algorithms are
               heavily and specifically tuned for short queries with low
               sequencing error rate. However, some sequencing platforms
               already produce longer reads and others are expected to become
               available soon. For longer reads, hashing-based software such as
               BLAT and SSAHA2 remain the only choices. Nonetheless, these
               methods are substantially slower than short-read aligners in
               terms of aligned bases per unit time. RESULTS: We designed and
               implemented a new algorithm, Burrows-Wheeler Aligner's
               Smith-Waterman Alignment (BWA-SW), to align long sequences up to
               1 Mb against a large sequence database (e.g. the human genome)
               with a few gigabytes of memory. The algorithm is as accurate as
               SSAHA2, more accurate than BLAT, and is several to tens of times
               faster than both. AVAILABILITY: http://bio-bwa.sourceforge.net",
  journal   = "Bioinformatics",
  publisher = "Oxford University Press (OUP)",
  volume    =  26,
  number    =  5,
  pages     = "589--595",
  month     =  mar,
  year      =  2010,
  language  = "en"
}
@ARTICLE{Camacho2009-hf,
  title     = "{BLAST+}: architecture and applications",
  author    = "Camacho, Christiam and Coulouris, George and Avagyan, Vahram and
               Ma, Ning and Papadopoulos, Jason and Bealer, Kevin and Madden,
               Thomas L",
  abstract  = "BACKGROUND: Sequence similarity searching is a very important
               bioinformatics task. While Basic Local Alignment Search Tool
               (BLAST) outperforms exact methods through its use of heuristics,
               the speed of the current BLAST software is suboptimal for very
               long queries or database sequences. There are also some
               shortcomings in the user-interface of the current command-line
               applications. RESULTS: We describe features and improvements of
               rewritten BLAST software and introduce new command-line
               applications. Long query sequences are broken into chunks for
               processing, in some cases leading to dramatically shorter run
               times. For long database sequences, it is possible to retrieve
               only the relevant parts of the sequence, reducing CPU time and
               memory usage for searches of short queries against databases of
               contigs or chromosomes. The program can now retrieve masking
               information for database sequences from the BLAST databases. A
               new modular software library can now access subject sequence
               data from arbitrary data sources. We introduce several new
               features, including strategy files that allow a user to save and
               reuse their favorite set of options. The strategy files can be
               uploaded to and downloaded from the NCBI BLAST web site.
               CONCLUSION: The new BLAST command-line applications, compared to
               the current BLAST tools, demonstrate substantial speed
               improvements for long queries as well as chromosome length
               database sequences. We have also improved the user interface of
               the command-line applications.",
  journal   = "BMC Bioinformatics",
  publisher = "Springer Science and Business Media LLC",
  volume    =  10,
  number    =  1,
  pages     = "421",
  month     =  dec,
  year      =  2009,
  language  = "en"
}
@ARTICLE{Altschul1997-oe,
  title     = "Gapped {BLAST} and {PSI-BLAST}: a new generation of protein
               database search programs",
  author    = "Altschul, S F and Madden, T L and Sch{\"a}ffer, A A and Zhang, J
               and Zhang, Z and Miller, W and Lipman, D J",
  abstract  = "The BLAST programs are widely used tools for searching protein
               and DNA databases for sequence similarities. For protein
               comparisons, a variety of definitional, algorithmic and
               statistical refinements described here permits the execution
               time of the BLAST programs to be decreased substantially while
               enhancing their sensitivity to weak similarities. A new
               criterion for triggering the extension of word hits, combined
               with a new heuristic for generating gapped alignments, yields a
               gapped BLAST program that runs at approximately three times the
               speed of the original. In addition, a method is introduced for
               automatically combining statistically significant alignments
               produced by BLAST into a position-specific score matrix, and
               searching the database using this matrix. The resulting
               Position-Specific Iterated BLAST (PSI-BLAST) program runs at
               approximately the same speed per iteration as gapped BLAST, but
               in many cases is much more sensitive to weak but biologically
               relevant sequence similarities. PSI-BLAST is used to uncover
               several new and interesting members of the BRCT superfamily.",
  journal   = "Nucleic Acids Res.",
  publisher = "Oxford University Press (OUP)",
  volume    =  25,
  number    =  17,
  pages     = "3389--3402",
  month     =  sep,
  year      =  1997,
  language  = "en"
}

@ARTICLE{Silva_e_Santos2012-qm,
  title     = "The {PhOCoe} Model--ergonomic pattern mapping in participatory
               design processes",
  author    = "Silva e Santos, Marcello",
  abstract  = "The discipline and practice of human factors and ergonomics is
               quite rich in terms of the availability of analysis, development
               and evaluation tools and methods for its various processes.
               However, we lack effective instruments to either map or regulate
               comprehensively and effectively, cognitive and organizational
               related impacts, especially the environmental ones. Moreover,
               when ergonomic transformations through design - such as a new
               workstation design or even an entire new facility - is at play,
               ergonomics professionals tend to stay at bay, relying solely on
               design professionals and engineers. There is vast empirical
               evidence showing that participation of ergonomists as project
               facilitators, may contribute to an effective professional
               synergy amongst the various stakeholders in a multidisciplinary
               venue. When that happens, everyone wins - users and designers
               alike -because eventual conflicts, raised up in the midst of
               options selection, are dissipated in exchange for more
               convergent design alternatives. This paper presents a method for
               participatory design, in which users are encouraged to actively
               participate in the whole design process by sharing their real
               work activities with the design team. The negotiated results
               inferred from the ergonomic action and translated into a new
               design, are then compiled into a ``Ergonomic Pattern Manual''.
               This handbook of ergonomics-oriented design guidelines contains
               essential guidelines to be consulted in recurrent design project
               situations in which similar patterns might be used. The main
               drive is simple: nobody knows better than workers themselves
               what an adequate workplace design solution (equipment,
               workstation, office layout) should be.",
  journal   = "Work",
  publisher = "IOS Press",
  volume    = "41 Suppl 1",
  pages     = "2643--2650",
  year      =  2012,
  language  = "en"
}

@ARTICLE{Tosello2012-kp,
  title     = "Conditions for the successful integration of Human and
               Organizational Factors ({HOF}) in the nuclear safety analysis",
  author    = "Tosello, Mich{\`e}le and L{\'e}v{\^e}que, Fran{\c c}oise and
               Dutillieu, St{\'e}phanie and Hernandez, Guillaume and Vautier,
               Jean-Fran{\c c}ois",
  abstract  = "This communication presents some elements which come from the
               experience feedback at CEA about the conditions for the
               successful integration of HOF in the nuclear safety analysis. To
               point out some of these conditions, one of the concepts proposed
               by Edgar Morin to describe the functioning of ``complex''
               systems: the dialogical principle has been used. The idea is to
               look for some dialogical pairs. The elements of this kind of
               pair are both complementary and antagonist to one another. Three
               dialogical pairs are presented in this communication. The first
               two pairs are related to the organization of the HOF network and
               the last one is related to the methods which are used to analyse
               the working situations. The three pairs are: specialist -
               non-specialist actors of the network, centralized - distributed
               human resources in the network and microscopic - macroscopic
               levels of HOF methods to analyse the working situations. To
               continuously improve these three dialogical pairs, it is
               important to keep the differences which exist between the two
               elements of a pair and to find and maintain a balance between
               the two elements of the pairs.",
  journal   = "Work",
  publisher = "IOS Press",
  volume    = "41 Suppl 1",
  pages     = "2656--2660",
  year      =  2012,
  language  = "en"
}

@ARTICLE{Corinne2012-tx,
  title     = "Analysis of organizational conditions for risk management: the
               case study of a petrochemical site",
  author    = "Corinne, Gaudart and Alain, Garrigou and Karine, Chassaing",
  abstract  = "This paper presents an ergonomic intervention in the
               petrochemical sector. The scheduled shutdown of one of the gas
               production sites has led the management to reduce the number of
               personnel on site, and then to get new recruits and experienced
               technicians from other sites as the policy for leaving personnel
               had not been properly planned, resulting in understaffing on
               site. Workers with seniority on the site, and who are also the
               most experienced do not accept the way newcomers are induced on
               site, whereas the management accuses them of resisting change.
               The intervention consisted in reconnecting local and corporate
               management through making the work activity visible and linking
               two sets of data that they held separately. Different types of
               analyses were made, work demography, decision making processes
               and tools used by the management, analysis of the building of
               career and work logics. Those different levels of analysis are
               gathered in macro-ergonomics, while showing the possible
               combinations between top down and bottom up approaches. The
               intervention resulted in concrete changes: HR simulation tool,
               training organisation, feedback.",
  journal   = "Work",
  publisher = "IOS Press",
  volume    = "41 Suppl 1",
  pages     = "2661--2667",
  year      =  2012,
  language  = "en"
}

@ARTICLE{Herrera2012-qm,
  title     = "Macroergomonics' contribution to the effectiveness of
               collaborative supply chains",
  author    = "Herrera, Sandra Mejias and Huatuco, Luisa Huaccho",
  abstract  = "This article presents a conceptual model that combines
               Macroergonomics and Supply chain. The authors combine their
               expertise on these individual topics, building on their previous
               research. The argument of the paper is that human factors are
               key to achieve effective supplier-customer collaboration. A
               conceptual model is presented, its elements and their
               interactions are explained. The Content-Context-Process is
               applied as a departing point to this model. Macroergonomics
               aspects considered are: a systemic approach, participatory
               ergonomics, formation of ergonomics teams and evaluation of
               ergonomics projects. The expected outcomes are: (a) improvement
               of production and productivity levels, (b) improvement of the
               product quality, (c) Reduction of absenteeism, (d) Improvement
               in the quality of work life (from the employees' perspective),
               and (e) increase in the employees' contribution rate of ideas
               for improvement. A case study was carried out at a vitroplant
               production organisation incorporating environmental aspects to
               obtain sustainable benefits.",
  journal   = "Work",
  publisher = "IOS Press",
  volume    = "41 Suppl 1",
  pages     = "2695--2700",
  year      =  2012,
  language  = "en"
}

@ARTICLE{Soares2012-us,
  title     = "Organizational issues that impact on non-use of equipment for
               individual protection: a view of ergonomics",
  author    = "Soares, Eva Bessa",
  abstract  = "The investigative focus of this paper is the issue of non-use of
               PPE (personal protective equipment) in a trading company of
               chilled and frozen food products. To conduct the study we have
               used an ergonomic work analysis that allowed us to highlight
               important organizational aspects that contribute to the non-use
               of such equipment. In conclusion, there are suggestions for
               minimizing problems.",
  journal   = "Work",
  publisher = "IOS Press",
  volume    = "41 Suppl 1",
  pages     = "2668--2674",
  year      =  2012,
  language  = "en"
}

@ARTICLE{Blome2012-dx,
  title     = "Visualization of regulations to support design and quality
               control--a long-term study",
  author    = "Blom{\'e}, Mikael",
  abstract  = "The aim of the study was to visualize design regulations of
               furniture by means of interactive technology based on earlier
               studies and practical examples. The usage of the visualized
               regulations was evaluated on two occasions: at the start when
               the first set of regulations was presented, and after six years
               of usage of all regulations. The visualized regulations were the
               result of a design process involving experts and potential users
               in collaboration with IKEA of Sweden AB. The evaluations by the
               different users showed a very positive response to using
               visualized regulations. The participative approach, combining
               expertise in specific regulations with visualization of
               guidelines, resulted in clear presentations of important
               regulations, and great attitudes among the users. These kinds of
               visualizations have proved to be applicable in a variety of
               product areas at IKEA, with a potential for further
               dissemination. It is likely that the approaches to design and
               visualized regulations in this case study could function in
               other branches.",
  journal   = "Work",
  publisher = "IOS Press",
  volume    = "41 Suppl 1",
  pages     = "2683--2685",
  year      =  2012,
  language  = "en"
}

@ARTICLE{Bitencourt2012-vu,
  title     = "Macroergonomic analysis of two different work organizations in a
               same sector of a luminary manufacturer",
  author    = "Bitencourt, Rosimeire Sedrez and Guimar{\~a}es, Lia Buarque de
               Macedo",
  abstract  = "This article presents the analysis of the effect of two
               different types of work organization (the traditional and a new
               mechanized, more segmented one) in the packing sector of a
               luminary manufacturing company in Curitiba, Brazil. A
               macroergonomic analysis was conducted to evaluate the workers
               satisfaction with the job; the possible associated postural
               risk, the level of body pain/discomfort and to compare the two
               models (traditional and mechanized). The mechanized model showed
               to involve higher postural risk, to generate more pain and less
               satisfaction, even in relation to the temperature, illumination,
               uniform and salary, which are the same for the two groups.
               Excluding job rotation that was well evaluated and should be
               adopted for all workers, the new model proved to be worse than
               the traditional although it also needs improvements.",
  journal   = "Work",
  publisher = "IOS Press",
  volume    = "41 Suppl 1",
  pages     = "2686--2694",
  year      =  2012,
  language  = "en"
}

@ARTICLE{Coelho2012-tk,
  title     = "Macroergonomic aspects in the design of development programs in
               {IDCs}",
  author    = "Coelho, Denis A and Ferrara, Patricia R and Couvinhas, Ana F and
               Lima, T{\^a}nia M and Walter, Jake K",
  abstract  = "This paper revisits three reports on ergonomic aspects of
               development initiatives taking place in Industrially Developing
               Countries (IDCs). These include a macro-ergonomics intervention
               in a habitation community in Cape Verde (aimed at designing
               solutions contributing to sustainable development), the
               evolution of poultry growers' control strategies as an
               integrative broiler operation is introduced in Mozambique, and a
               set of macro-ergonomic considerations related to the Agro
               Forestry Village Project in Mozambique. The paper seeks to set
               the reviewed development endeavors against the backdrop of the
               goals of ergonomics interventions. This reflection may inform
               development agents in future processes of design and
               implementation of integrated community and work systems
               transformation.",
  journal   = "Work",
  publisher = "IOS Press",
  volume    = "41 Suppl 1",
  pages     = "2651--2655",
  year      =  2012,
  language  = "en"
}

@ARTICLE{Scariot2012-bl,
  title     = "Understanding the collaborative-participatory design",
  author    = "Scariot, Cristiele A and Heemann, Adriano and Padovani,
               Stephania",
  abstract  = "In this study, the role of collaboration in design is discussed,
               placing emphasis on how to include end-users in the development
               process. The study is based on a literature review focusing on
               aspects of collaboration in design, usability and human factors.
               Thereby, it introduces, compares and contrasts the
               characteristics of both collaborative and user-centered design
               perspectives, leading to the collaborative-participatory design
               approach. Finally, the advantages, disadvantages and precautions
               of implementing collaborative and participatory models are
               pointed out.",
  journal   = "Work",
  publisher = "IOS Press",
  volume    = "41 Suppl 1",
  pages     = "2701--2705",
  year      =  2012,
  language  = "en"
}

@ARTICLE{Zulch2012-ul,
  title     = "Analysis of the strain on employees in the retail sector
               considering work-life balance",
  author    = "Z{\"u}lch, Gert and Stock, Patricia and Schmidt, Daniel",
  abstract  = "Many companies currently strive to support their employees'
               work-life balance through appropriate measures in order to
               improve employees' loyalty towards the company and to recruit
               new employees. In this context, flexibility in the area of
               working times is a measure that can influence employees' private
               lives immensely. This is why the individualisation of working
               time arrangements has been accorded high importance in current
               discussions on work-life balance. In this area, best practice
               examples can be found showing how working-time arrangements can
               improve the situation of the employees. It should be noted,
               however, that there is not one single perfect working-time
               model. A working-time model must always be adapted specifically
               to the actual situation of the company and the employees.
               Therefore, a targeted analysis of the challenges facing the
               company and the demands on the employees is essential for the
               creation of an appropriate working time policy. In particular,
               the employees' working-time preferences must be appropriately
               taken into account. Owing, however, to a combination of
               organisational complications and legal data protection
               restrictions, it is for the most part impossible to meet these
               working-time preferences in their entirety. This paper, which is
               based on an employee survey, illustrates the strain on employees
               in the retail sector and identifies different types of
               working-time preferences.",
  journal   = "Work",
  publisher = "IOS Press",
  volume    = "41 Suppl 1",
  pages     = "2675--2682",
  year      =  2012,
  language  = "en"
}

@ARTICLE{Altschul1990-xn,
  title     = "Basic local alignment search tool",
  author    = "Altschul, S F and Gish, W and Miller, W and Myers, E W and
               Lipman, D J",
  abstract  = "A new approach to rapid sequence comparison, basic local
               alignment search tool (BLAST), directly approximates alignments
               that optimize a measure of local similarity, the maximal segment
               pair (MSP) score. Recent mathematical results on the stochastic
               properties of MSP scores allow an analysis of the performance of
               this method as well as the statistical significance of
               alignments it generates. The basic algorithm is simple and
               robust; it can be implemented in a number of ways and applied in
               a variety of contexts including straightforward DNA and protein
               sequence database searches, motif searches, gene identification
               searches, and in the analysis of multiple regions of similarity
               in long DNA sequences. In addition to its flexibility and
               tractability to mathematical analysis, BLAST is an order of
               magnitude faster than existing sequence comparison tools of
               comparable sensitivity.",
  journal   = "J. Mol. Biol.",
  publisher = "Elsevier BV",
  volume    =  215,
  number    =  3,
  pages     = "403--410",
  month     =  oct,
  year      =  1990,
  language  = "en"
}

@Article{pmid31742321,
   Author="Aramaki, T.  and Blanc-Mathieu, R.  and Endo, H.  and Ohkubo, K.  and Kanehisa, M.  and Goto, S.  and Ogata, H. ",
   Title="{{K}ofam{K}{O}{A}{L}{A}: {K}{E}{G}{G} {O}rtholog assignment based on profile {H}{M}{M} and adaptive score threshold}",
   Journal="Bioinformatics",
   Year="2020",
   Volume="36",
   Number="7",
   Pages="2251--2252",
   Month="04"
}

@article{10.1093/nargab/lqaa026,
    author = {Brůna, Tomáš and Lomsadze, Alexandre and Borodovsky, Mark},
    title = "{GeneMark-EP+: eukaryotic gene prediction with self-training in the space of genes and proteins}",
    journal = {NAR Genomics and Bioinformatics},
    volume = {2},
    number = {2},
    year = {2020},
    month = {05},
    abstract = "{We have made several steps toward creating a fast and accurate algorithm for gene prediction in eukaryotic genomes. First, we introduced an automated method for efficient ab initio gene finding, GeneMark-ES, with parameters trained in iterative unsupervised mode. Next, in GeneMark-ET we proposed a method of integration of unsupervised training with information on intron positions revealed by mapping short RNA reads. Now we describe GeneMark-EP, a tool that utilizes another source of external information, a protein database, readily available prior to the start of a sequencing project. A new specialized pipeline, ProtHint, initiates massive protein mapping to genome and extracts hints to splice sites and translation start and stop sites of potential genes. GeneMark-EP uses the hints to improve estimation of model parameters as well as to adjust coordinates of predicted genes if they disagree with the most reliable hints (the -EP+ mode). Tests of GeneMark-EP and -EP+ demonstrated improvements in gene prediction accuracy in comparison with GeneMark-ES, while the GeneMark-EP+ showed higher accuracy than GeneMark-ET. We have observed that the most pronounced improvements in gene prediction accuracy happened in large eukaryotic genomes.}",
    issn = {2631-9268},
    doi = {10.1093/nargab/lqaa026},
    url = {https://doi.org/10.1093/nargab/lqaa026},
    note = {lqaa026},
    eprint = {https://academic.oup.com/nargab/article-pdf/2/2/lqaa026/34054524/lqaa026.pdf},
}



@Inbook{Sallet2019,
author="Sallet, Erika
and Gouzy, J{\'e}r{\^o}me
and Schiex, Thomas",
editor="Kollmar, Martin",
title="EuGene: An Automated Integrative Gene Finder for Eukaryotes and Prokaryotes",
bookTitle="Gene Prediction: Methods and Protocols ",
year="2019",
publisher="Springer New York",
address="New York, NY",
pages="97--120",
abstract="EuGene is an integrative gene finder applicable to both prokaryotic and eukaryotic genomes. EuGene annotated its first genome in 1999. Starting from genomic DNA sequences representing a complete genome, EuGene is able to predict the major transcript units in the genome from a variety of sources of information: statistical information, similarities with known transcripts and proteins, but also any GFF3 structured information supporting the presence or absence of specific types of elements. EuGene has been used to find genes in the plants Arabidopsis thaliana, Medicago truncatula, and Theobroma cacao; tomato, sunflower, and Rosa genomes; and in the nematode Meloidogyne incognita genome, among many others. The large fraction of plant in this list probably influenced EuGene development, especially in its capacities to withstand a genome with a large number of repeated regions and transposable elements.",
isbn="978-1-4939-9173-0",
doi="10.1007/978-1-4939-9173-0_6",
url="https://doi.org/10.1007/978-1-4939-9173-0_6"
}

@article{10.1093/bioinformatics/btv033,
    author = {Li, Dinghua and Liu, Chi-Man and Luo, Ruibang and Sadakane, Kunihiko and Lam, Tak-Wah},
    title = "{MEGAHIT: an ultra-fast single-node solution for large and complex metagenomics assembly via succinct de Bruijn graph}",
    journal = {Bioinformatics},
    volume = {31},
    number = {10},
    pages = {1674-1676},
    year = {2015},
    month = {01},
    abstract = "{Summary: MEGAHIT is a NGS de novo assembler for assembling large and complex metagenomics data in a time- and cost-efficient manner. It finished assembling a soil metagenomics dataset with 252 Gbps in 44.1 and 99.6 h on a single computing node with and without a graphics processing unit, respectively. MEGAHIT assembles the data as a whole, i.e. no pre-processing like partitioning and normalization was needed. When compared with previous methods on assembling the soil data, MEGAHIT generated a three-time larger assembly, with longer contig N50 and average contig length; furthermore, 55.8\\% of the reads were aligned to the assembly, giving a fourfold improvement.Availability and implementation: The source code of MEGAHIT is freely available at https://github.com/voutcn/megahit under GPLv3 license.Contact:rb@l3-bioinfo.com or twlam@cs.hku.hkSupplementary information: Supplementary data are available at Bioinformatics online.}",
    issn = {1367-4803},
    doi = {10.1093/bioinformatics/btv033},
    url = {https://doi.org/10.1093/bioinformatics/btv033},
    eprint = {https://academic.oup.com/bioinformatics/article-pdf/31/10/1674/17085710/btv033.pdf},
}



@article{10.1093/bioinformatics/bts174,
    author = {Peng, Yu and Leung, Henry C. M. and Yiu, S. M. and Chin, Francis Y. L.},
    title = "{IDBA-UD: a de novo assembler for single-cell and metagenomic sequencing data with highly uneven depth}",
    journal = {Bioinformatics},
    volume = {28},
    number = {11},
    pages = {1420-1428},
    year = {2012},
    month = {04},
    abstract = "{Motivation: Next-generation sequencing allows us to sequence reads from a microbial environment using single-cell sequencing or metagenomic sequencing technologies. However, both technologies suffer from the problem that sequencing depth of different regions of a genome or genomes from different species are highly uneven. Most existing genome assemblers usually have an assumption that sequencing depths are even. These assemblers fail to construct correct long contigs.Results: We introduce the IDBA-UD algorithm that is based on the de Bruijn graph approach for assembling reads from single-cell sequencing or metagenomic sequencing technologies with uneven sequencing depths. Several non-trivial techniques have been employed to tackle the problems. Instead of using a simple threshold, we use multiple depthrelative thresholds to remove erroneous k-mers in both low-depth and high-depth regions. The technique of local assembly with paired-end information is used to solve the branch problem of low-depth short repeat regions. To speed up the process, an error correction step is conducted to correct reads of high-depth regions that can be aligned to highconfident contigs. Comparison of the performances of IDBA-UD and existing assemblers (Velvet, Velvet-SC, SOAPdenovo and Meta-IDBA) for different datasets, shows that IDBA-UD can reconstruct longer contigs with higher accuracy.Availability: The IDBA-UD toolkit is available at our website http://www.cs.hku.hk/~alse/idba\_udContact:chin@cs.hku.hk}",
    issn = {1367-4803},
    doi = {10.1093/bioinformatics/bts174},
    url = {https://doi.org/10.1093/bioinformatics/bts174},
    eprint = {https://academic.oup.com/bioinformatics/article-pdf/28/11/1420/742285/bts174.pdf},
}



@Article{pmid10592173,
   Author="Kanehisa, M.  and Goto, S. ",
   Title="{{K}{E}{G}{G}: kyoto encyclopedia of genes and genomes}",
   Journal="Nucleic Acids Res",
   Year="2000",
   Volume="28",
   Number="1",
   Pages="27--30",
   Month="Jan"
}
@Article{pmid31441146,
   Author="Kanehisa, M. ",
   Title="{{T}oward understanding the origin and evolution of cellular organisms}",
   Journal="Protein Sci",
   Year="2019",
   Volume="28",
   Number="11",
   Pages="1947--1951",
   Month="11"
}
@Article{pmid33125081,
   Author="Kanehisa, M.  and Furumichi, M.  and Sato, Y.  and Ishiguro-Watanabe, M.  and Tanabe, M. ",
   Title="{{K}{E}{G}{G}: integrating viruses and cellular organisms}",
   Journal="Nucleic Acids Res",
   Year="2021",
   Volume="49",
   Number="D1",
   Pages="D545-D551",
   Month="01"
}

@misc{krakenmanual,
  Title="Kraken taxonomic sequence classification system: Operating Manual", 
  url={https://ccb.jhu.edu/software/kraken/MANUAL.html}
} 