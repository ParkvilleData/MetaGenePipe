@ARTICLE{Arden2017-as,
  title    = "{Detection of Toscana virus from an adult traveler returning to
              Australia with encephalitis}",
  author   = "Arden, Katherine E and Heney, Claire and Shaban, Babak and Nimmo,
              Graeme R and Nissen, Michael D and Sloots, Theo P and Mackay, Ian
              M",
  abstract = "Toscana virus (TOSV) is identified in sandflies, animals, and
              humans around the Mediterranean Sea. TOSV has not been reported
              in Australia. During investigations of cerebrospinal fluid
              samples from patients with encephalitis, TOSV genetic sequences
              were identified in a traveler returning to Australia from Europe.
              TOSV should be considered, especially during May to October, in
              travelers to Australia who embarked in countries in and around
              the Mediterranean Sea and who subsequently present for medical
              care because of neurological symptoms.",
  journal  = "J. Med. Virol.",
  volume   =  89,
  number   =  10,
  pages    = "1861--1864",
  month    =  oct,
  year     =  2017,
  doi      = "10.1002/jmv.24839",
  keywords = "Phlebovirus; Toscana virus; encephalitis; high throughput
              sequencing; travel",
  language = "en"
}
@ARTICLE{Roediger2018-lq,
  title     = "{An atypical Parvovirus drives chronic tubulointerstitial
               nephropathy and kidney fibrosis}",
  author    = "Roediger, Ben and Lee, Quintin and Tikoo, Shweta and Cobbin,
               Joanna C A and Henderson, James M and Jormakka, Mika and
               O'Rourke, Matthew B and Padula, Matthew P and Pinello, Natalia
               and Henry, Marisa and Wynne, Maria and Santagostino, Sara F and
               Brayton, Cory F and Rasmussen, Lorna and Lisowski, Leszek and
               Tay, Szun S and Harris, David C and Bertram, John F and Dowling,
               John P and Bertolino, Patrick and Lai, Jack H and Wu, Wengen and
               Bachovchin, William W and Wong, Justin J-L and Gorrell, Mark D
               and Shaban, Babak and Holmes, Edward C and Jolly, Christopher J
               and Monette, S{\'e}bastien and Weninger, Wolfgang",
  abstract  = "The occurrence of a spontaneous nephropathy with intranuclear
               inclusions in laboratory mice has puzzled pathologists for over
               4 decades, because its etiology remains elusive. The condition
               is more severe in immunodeficient animals, suggesting an
               infectious cause. Using metagenomics, we identify the causative
               agent as an atypical virus, termed ``mouse kidney parvovirus''
               (MKPV), belonging to a divergent genus of Parvoviridae. MKPV was
               identified in animal facilities in Australia and North America,
               is transmitted via a fecal-oral or urinary-oral route, and is
               controlled by the adaptive immune system. Detailed analysis of
               the clinical course and histopathological features demonstrated
               a stepwise progression of pathology ranging from sporadic
               tubular inclusions to tubular degeneration and interstitial
               fibrosis and culminating in renal failure. In summary, we
               identify a widely distributed pathogen in laboratory mice and
               establish MKPV-induced nephropathy as a new tool for elucidating
               mechanisms of tubulointerstitial fibrosis that shares molecular
               features with chronic kidney disease in humans.",
  journal   = "Cell",
  publisher = "Elsevier BV",
  volume    =  175,
  number    =  2,
  doi       = "10.1016/j.cell.2018.08.013",
  pages     = "530--543.e24",
  month     =  oct,
  year      =  2018,
  keywords  = "Parvoviridae; chronic kidney disease; fibrosis; inclusion body
               nephropathy; parvovirus; tubulointerstitial fibrosis; viral
               metagenomics",
  copyright = "http://www.elsevier.com/open-access/userlicense/1.0/",
  language  = "en"
}
@article{langmead2012,
    author = "Langmead, Ben and Salzberg, Steven L",
    type = "Journal Article",
    title = "{{Fast gapped-read alignment with Bowtie 2}}",
    journal = "Nature Methods",
    number = "4",
    doi = "10.1038/nmeth.1923",
    volume = "9",
    pages = "357--359",
    url = "https://doi.org/10.1038/nmeth.1923",
    year = "2012",
    abstract = "The Bowtie 2 software achieves fast, sensitive, accurate and memory-efficient gapped alignment of sequencing reads using the full-text minute index and hardware-accelerated dynamic programming algorithms.",
    issn = "1548-7105",
    da = "2012/04/01"
}
@misc{Andrews:2010tn,
  added-at = {2012-06-02T05:59:56.000+0200},
  author = {Andrews, S.},
  biburl = {https://www.bibsonomy.org/bibtex/2b6052877491828ab53d3449be9b293b3/ozborn},
  date-added = {2012-06-01 16:59:33 -0500},
  date-modified = {2012-06-01 16:59:49 -0500},
  interhash = {f230a919c34360709aa298734d63dca3},
  intrahash = {b6052877491828ab53d3449be9b293b3},
  keywords = {imported},
  timestamp = {2012-06-03T07:20:30.000+0200},
  title = {{FASTQC. A quality control tool for high throughput sequence data}},
  year = 2010,
  url = "https://www.bioinformatics.babraham.ac.uk/projects/fastqc/"
}
@ARTICLE{Magoc2011-gb,
  title     = "{FLASH}: fast length adjustment of short reads to improve genome
               assemblies",
  author    = "Mago{\v c}, Tanja and Salzberg, Steven L",
  abstract  = "MOTIVATION: Next-generation sequencing technologies generate
               very large numbers of short reads. Even with very deep genome
               coverage, short read lengths cause problems in de novo
               assemblies. The use of paired-end libraries with a fragment size
               shorter than twice the read length provides an opportunity to
               generate much longer reads by overlapping and merging read pairs
               before assembling a genome. RESULTS: We present FLASH, a fast
               computational tool to extend the length of short reads by
               overlapping paired-end reads from fragment libraries that are
               sufficiently short. We tested the correctness of the tool on one
               million simulated read pairs, and we then applied it as a
               pre-processor for genome assemblies of Illumina reads from the
               bacterium Staphylococcus aureus and human chromosome 14. FLASH
               correctly extended and merged reads >99\% of the time on
               simulated reads with an error rate of <1\%. With adequately set
               parameters, FLASH correctly merged reads over 90\% of the time
               even when the reads contained up to 5\% errors. When FLASH was
               used to extend reads prior to assembly, the resulting assemblies
               had substantially greater N50 lengths for both contigs and
               scaffolds. AVAILABILITY AND IMPLEMENTATION: The FLASH system is
               implemented in C and is freely available as open-source code at
               http://www.cbcb.umd.edu/software/flash. CONTACT:
               t.magoc@gmail.com.",
  journal   = "Bioinformatics",
  publisher = "Oxford University Press (OUP)",
  volume    =  27,
  number    =  21,
  pages     = "2957--2963",
  month     =  nov,
  year      =  2011,
  language  = "en",
  doi="10.1093/bioinformatics/btr507"
}

@ARTICLE{Schmieder2011-jr,
  title     = "Fast identification and removal of sequence contamination from
               genomic and metagenomic datasets",
  author    = "Schmieder, Robert and Edwards, Robert",
  abstract  = "High-throughput sequencing technologies have strongly impacted
               microbiology, providing a rapid and cost-effective way of
               generating draft genomes and exploring microbial diversity.
               However, sequences obtained from impure nucleic acid
               preparations may contain DNA from sources other than the sample.
               Those sequence contaminations are a serious concern to the
               quality of the data used for downstream analysis, causing
               misassembly of sequence contigs and erroneous conclusions.
               Therefore, the removal of sequence contaminants is a necessary
               and required step for all sequencing projects. We developed
               DeconSeq, a robust framework for the rapid, automated
               identification and removal of sequence contamination in
               longer-read datasets (150 bp mean read length). DeconSeq is
               publicly available as standalone and web-based versions. The
               results can be exported for subsequent analysis, and the
               databases used for the web-based version are automatically
               updated on a regular basis. DeconSeq categorizes possible
               contamination sequences, eliminates redundant hits with higher
               similarity to non-contaminant genomes, and provides graphical
               visualizations of the alignment results and classifications.
               Using DeconSeq, we conducted an analysis of possible human DNA
               contamination in 202 previously published microbial and viral
               metagenomes and found possible contamination in 145 (72\%)
               metagenomes with as high as 64\% contaminating sequences. This
               new framework allows scientists to automatically detect and
               efficiently remove unwanted sequence contamination from their
               datasets while eliminating critical limitations of current
               methods. DeconSeq's web interface is simple and user-friendly.
               The standalone version allows offline analysis and integration
               into existing data processing pipelines. DeconSeq's results
               reveal whether the sequencing experiment has succeeded, whether
               the correct sample was sequenced, and whether the sample
               contains any sequence contamination from DNA preparation or
               host. In addition, the analysis of 202 metagenomes demonstrated
               significant contamination of the non-human associated
               metagenomes, suggesting that this method is appropriate for
               screening all metagenomes. DeconSeq is available at
               http://deconseq.sourceforge.net/.",
  journal   = "PLoS One",
  publisher = "Public Library of Science (PLoS)",
  volume    =  6,
  number    =  3,
  pages     = "e17288",
  month     =  mar,
  year      =  2011,
  doi       = "10.1371/journal.pone.0017288",
  language  = "en"
}
@ARTICLE{Hyatt2010-zh,
  title     = "Prodigal: prokaryotic gene recognition and translation
               initiation site identification",
  author    = "Hyatt, Doug and Chen, Gwo-Liang and Locascio, Philip F and Land,
               Miriam L and Larimer, Frank W and Hauser, Loren J",
  abstract  = "BACKGROUND: The quality of automated gene prediction in
               microbial organisms has improved steadily over the past decade,
               but there is still room for improvement. Increasing the number
               of correct identifications, both of genes and of the translation
               initiation sites for each gene, and reducing the overall number
               of false positives, are all desirable goals. RESULTS: With our
               years of experience in manually curating genomes for the Joint
               Genome Institute, we developed a new gene prediction algorithm
               called Prodigal (PROkaryotic DYnamic programming Gene-finding
               ALgorithm). With Prodigal, we focused specifically on the three
               goals of improved gene structure prediction, improved
               translation initiation site recognition, and reduced false
               positives. We compared the results of Prodigal to existing
               gene-finding methods to demonstrate that it met each of these
               objectives. CONCLUSION: We built a fast, lightweight, open
               source gene prediction program called Prodigal
               http://compbio.ornl.gov/prodigal/. Prodigal achieved good
               results compared to existing methods, and we believe it will be
               a valuable asset to automated microbial annotation pipelines.",
  journal   = "BMC Bioinformatics",
  publisher = "Springer Nature",
  volume    =  11,
  number    =  1,
  pages     = "119",
  month     =  mar,
  year      =  2010,
  language  = "en",
  doi="10.1186/1471-2105-11-119"
}
@ARTICLE{Buchfink2015-rn,
  title     = "Fast and sensitive protein alignment using {DIAMOND}",
  author    = "Buchfink, Benjamin and Xie, Chao and Huson, Daniel H",
  abstract  = "The alignment of sequencing reads against a protein reference
               database is a major computational bottleneck in metagenomics and
               data-intensive evolutionary projects. Although recent tools
               offer improved performance over the gold standard BLASTX, they
               exhibit only a modest speedup or low sensitivity. We introduce
               DIAMOND, an open-source algorithm based on double indexing that
               is 20,000 times faster than BLASTX on short reads and has a
               similar degree of sensitivity.",
  journal   = "Nat. Methods",
  publisher = "Springer Science and Business Media LLC",
  volume    =  12,
  number    =  1,
  pages     = "59--60",
  month     =  jan,
  year      =  2015,
  language  = "en",
  doi="10.1038/nmeth.3176"
}
@ARTICLE{Li2010-nl,
  title     = "Fast and accurate long-read alignment with {Burrows-Wheeler}
               transform",
  author    = "Li, Heng and Durbin, Richard",
  abstract  = "MOTIVATION: Many programs for aligning short sequencing reads to
               a reference genome have been developed in the last 2 years. Most
               of them are very efficient for short reads but inefficient or
               not applicable for reads >200 bp because the algorithms are
               heavily and specifically tuned for short queries with low
               sequencing error rate. However, some sequencing platforms
               already produce longer reads and others are expected to become
               available soon. For longer reads, hashing-based software such as
               BLAT and SSAHA2 remain the only choices. Nonetheless, these
               methods are substantially slower than short-read aligners in
               terms of aligned bases per unit time. RESULTS: We designed and
               implemented a new algorithm, Burrows-Wheeler Aligner's
               Smith-Waterman Alignment (BWA-SW), to align long sequences up to
               1 Mb against a large sequence database (e.g. the human genome)
               with a few gigabytes of memory. The algorithm is as accurate as
               SSAHA2, more accurate than BLAT, and is several to tens of times
               faster than both. AVAILABILITY: http://bio-bwa.sourceforge.net",
  journal   = "Bioinformatics",
  publisher = "Oxford University Press (OUP)",
  volume    =  26,
  number    =  5,
  pages     = "589--595",
  month     =  mar,
  year      =  2010,
  language  = "en",
  doi="10.1093/bioinformatics/btp698"
}
@ARTICLE{Camacho2009-hf,
  title     = "{BLAST+}: architecture and applications",
  author    = "Camacho, Christiam and Coulouris, George and Avagyan, Vahram and
               Ma, Ning and Papadopoulos, Jason and Bealer, Kevin and Madden,
               Thomas L",
  abstract  = "BACKGROUND: Sequence similarity searching is a very important
               bioinformatics task. While Basic Local Alignment Search Tool
               (BLAST) outperforms exact methods through its use of heuristics,
               the speed of the current BLAST software is suboptimal for very
               long queries or database sequences. There are also some
               shortcomings in the user-interface of the current command-line
               applications. RESULTS: We describe features and improvements of
               rewritten BLAST software and introduce new command-line
               applications. Long query sequences are broken into chunks for
               processing, in some cases leading to dramatically shorter run
               times. For long database sequences, it is possible to retrieve
               only the relevant parts of the sequence, reducing CPU time and
               memory usage for searches of short queries against databases of
               contigs or chromosomes. The program can now retrieve masking
               information for database sequences from the BLAST databases. A
               new modular software library can now access subject sequence
               data from arbitrary data sources. We introduce several new
               features, including strategy files that allow a user to save and
               reuse their favorite set of options. The strategy files can be
               uploaded to and downloaded from the NCBI BLAST web site.
               CONCLUSION: The new BLAST command-line applications, compared to
               the current BLAST tools, demonstrate substantial speed
               improvements for long queries as well as chromosome length
               database sequences. We have also improved the user interface of
               the command-line applications.",
  journal   = "BMC Bioinformatics",
  publisher = "Springer Science and Business Media LLC",
  volume    =  10,
  number    =  1,
  pages     = "421",
  month     =  dec,
  year      =  2009,
  language  = "en",
  doi="10.1186/1471-2105-10-421"
}
@ARTICLE{Altschul1997-oe,
  title     = "Gapped {BLAST} and {PSI-BLAST}: a new generation of protein
               database search programs",
  author    = "Altschul, S F and Madden, T L and Sch{\"a}ffer, A A and Zhang, J
               and Zhang, Z and Miller, W and Lipman, D J",
  abstract  = "The BLAST programs are widely used tools for searching protein
               and DNA databases for sequence similarities. For protein
               comparisons, a variety of definitional, algorithmic and
               statistical refinements described here permits the execution
               time of the BLAST programs to be decreased substantially while
               enhancing their sensitivity to weak similarities. A new
               criterion for triggering the extension of word hits, combined
               with a new heuristic for generating gapped alignments, yields a
               gapped BLAST program that runs at approximately three times the
               speed of the original. In addition, a method is introduced for
               automatically combining statistically significant alignments
               produced by BLAST into a position-specific score matrix, and
               searching the database using this matrix. The resulting
               Position-Specific Iterated BLAST (PSI-BLAST) program runs at
               approximately the same speed per iteration as gapped BLAST, but
               in many cases is much more sensitive to weak but biologically
               relevant sequence similarities. PSI-BLAST is used to uncover
               several new and interesting members of the BRCT superfamily.",
  journal   = "Nucleic Acids Research",
  publisher = "Oxford University Press",
  volume    =  25,
  number    =  17,
  pages     = "3389--3402",
  month     =  sep,
  year      =  1997,
  language  = "en",
  doi = "10.1093/nar/25.17.3389"
}

@ARTICLE{Silva_e_Santos2012-qm,
  title     = "The {PhOCoe} Model--ergonomic pattern mapping in participatory
               design processes",
  author    = "Silva e Santos, Marcello",
  abstract  = "The discipline and practice of human factors and ergonomics is
               quite rich in terms of the availability of analysis, development
               and evaluation tools and methods for its various processes.
               However, we lack effective instruments to either map or regulate
               comprehensively and effectively, cognitive and organizational
               related impacts, especially the environmental ones. Moreover,
               when ergonomic transformations through design - such as a new
               workstation design or even an entire new facility - is at play,
               ergonomics professionals tend to stay at bay, relying solely on
               design professionals and engineers. There is vast empirical
               evidence showing that participation of ergonomists as project
               facilitators, may contribute to an effective professional
               synergy amongst the various stakeholders in a multidisciplinary
               venue. When that happens, everyone wins - users and designers
               alike -because eventual conflicts, raised up in the midst of
               options selection, are dissipated in exchange for more
               convergent design alternatives. This paper presents a method for
               participatory design, in which users are encouraged to actively
               participate in the whole design process by sharing their real
               work activities with the design team. The negotiated results
               inferred from the ergonomic action and translated into a new
               design, are then compiled into a ``Ergonomic Pattern Manual''.
               This handbook of ergonomics-oriented design guidelines contains
               essential guidelines to be consulted in recurrent design project
               situations in which similar patterns might be used. The main
               drive is simple: nobody knows better than workers themselves
               what an adequate workplace design solution (equipment,
               workstation, office layout) should be.",
  journal   = "Work",
  publisher = "IOS Press",
  volume    = "41 Suppl 1",
  pages     = "2643--2650",
  year      =  2012,
  doi       = "10.3233/WOR-2012-0507-2643",
  language  = "en"
}

@ARTICLE{Tosello2012-kp,
  title     = "Conditions for the successful integration of Human and
               Organizational Factors ({HOF}) in the nuclear safety analysis",
  author    = "Tosello, Mich{\`e}le and L{\'e}v{\^e}que, Fran{\c c}oise and
               Dutillieu, St{\'e}phanie and Hernandez, Guillaume and Vautier,
               Jean-Fran{\c c}ois",
  abstract  = "This communication presents some elements which come from the
               experience feedback at CEA about the conditions for the
               successful integration of HOF in the nuclear safety analysis. To
               point out some of these conditions, one of the concepts proposed
               by Edgar Morin to describe the functioning of ``complex''
               systems: the dialogical principle has been used. The idea is to
               look for some dialogical pairs. The elements of this kind of
               pair are both complementary and antagonist to one another. Three
               dialogical pairs are presented in this communication. The first
               two pairs are related to the organization of the HOF network and
               the last one is related to the methods which are used to analyse
               the working situations. The three pairs are: specialist -
               non-specialist actors of the network, centralized - distributed
               human resources in the network and microscopic - macroscopic
               levels of HOF methods to analyse the working situations. To
               continuously improve these three dialogical pairs, it is
               important to keep the differences which exist between the two
               elements of a pair and to find and maintain a balance between
               the two elements of the pairs.",
  journal   = "Work",
  publisher = "IOS Press",
  volume    = "41 Suppl 1",
  pages     = "2656--2660",
  doi       = "10.3233/wor-2012-0508-2656",
  year      =  2012,
  language  = "en"
}

@ARTICLE{Corinne2012-tx,
  title     = "Analysis of organizational conditions for risk management: the
               case study of a petrochemical site",
  author    = "Corinne, Gaudart and Alain, Garrigou and Karine, Chassaing",
  abstract  = "This paper presents an ergonomic intervention in the
               petrochemical sector. The scheduled shutdown of one of the gas
               production sites has led the management to reduce the number of
               personnel on site, and then to get new recruits and experienced
               technicians from other sites as the policy for leaving personnel
               had not been properly planned, resulting in understaffing on
               site. Workers with seniority on the site, and who are also the
               most experienced do not accept the way newcomers are induced on
               site, whereas the management accuses them of resisting change.
               The intervention consisted in reconnecting local and corporate
               management through making the work activity visible and linking
               two sets of data that they held separately. Different types of
               analyses were made, work demography, decision making processes
               and tools used by the management, analysis of the building of
               career and work logics. Those different levels of analysis are
               gathered in macro-ergonomics, while showing the possible
               combinations between top down and bottom up approaches. The
               intervention resulted in concrete changes: HR simulation tool,
               training organisation, feedback.",
  journal   = "Work",
  publisher = "IOS Press",
  volume    = "41 Suppl 1",
  pages     = "2661--2667",
  year      =  2012,
  doi       = "10.3233/wor-2012-1032-2661",
  language  = "en"
}




@ARTICLE{Altschul1990-xn,
  title     = "Basic local alignment search tool",
  author    = "Altschul, S F and Gish, W and Miller, W and Myers, E W and
               Lipman, D J",
  abstract  = "A new approach to rapid sequence comparison, basic local
               alignment search tool (BLAST), directly approximates alignments
               that optimize a measure of local similarity, the maximal segment
               pair (MSP) score. Recent mathematical results on the stochastic
               properties of MSP scores allow an analysis of the performance of
               this method as well as the statistical significance of
               alignments it generates. The basic algorithm is simple and
               robust; it can be implemented in a number of ways and applied in
               a variety of contexts including straightforward DNA and protein
               sequence database searches, motif searches, gene identification
               searches, and in the analysis of multiple regions of similarity
               in long DNA sequences. In addition to its flexibility and
               tractability to mathematical analysis, BLAST is an order of
               magnitude faster than existing sequence comparison tools of
               comparable sensitivity.",
  journal   = "J. Mol. Biol.",
  publisher = "Elsevier BV",
  volume    =  215,
  number    =  3,
  pages     = "403--410",
  month     =  oct,
  year      =  1990,
  language  = "en",
  doi = "10.1016/S0022-2836(05)80360-2"
}

@Article{pmid31742321,
   Author="Aramaki, T.  and Blanc-Mathieu, R.  and Endo, H.  and Ohkubo, K.  and Kanehisa, M.  and Goto, S.  and Ogata, H. ",
   Title="{{K}ofam{K}{O}{A}{L}{A}: {K}{E}{G}{G} {O}rtholog assignment based on profile {H}{M}{M} and adaptive score threshold}",
   Journal="Bioinformatics",
   Year="2020",
   Volume="36",
   Number="7",
   Pages="2251--2252",
   Month="04",
   doi="10.1093/bioinformatics/btz859"
}

@article{10.1093/nargab/lqaa026,
    author = {Brůna, Tomáš and Lomsadze, Alexandre and Borodovsky, Mark},
    title = "{GeneMark-EP+: eukaryotic gene prediction with self-training in the space of genes and proteins}",
    journal = {NAR Genomics and Bioinformatics},
    volume = {2},
    number = {2},
    year = {2020},
    month = {05},
    abstract = "{We have made several steps toward creating a fast and accurate algorithm for gene prediction in eukaryotic genomes. First, we introduced an automated method for efficient ab initio gene finding, GeneMark-ES, with parameters trained in iterative unsupervised mode. Next, in GeneMark-ET we proposed a method of integration of unsupervised training with information on intron positions revealed by mapping short RNA reads. Now we describe GeneMark-EP, a tool that utilizes another source of external information, a protein database, readily available prior to the start of a sequencing project. A new specialized pipeline, ProtHint, initiates massive protein mapping to genome and extracts hints to splice sites and translation start and stop sites of potential genes. GeneMark-EP uses the hints to improve estimation of model parameters as well as to adjust coordinates of predicted genes if they disagree with the most reliable hints (the -EP+ mode). Tests of GeneMark-EP and -EP+ demonstrated improvements in gene prediction accuracy in comparison with GeneMark-ES, while the GeneMark-EP+ showed higher accuracy than GeneMark-ET. We have observed that the most pronounced improvements in gene prediction accuracy happened in large eukaryotic genomes.}",
    issn = {2631-9268},
    doi = {10.1093/nargab/lqaa026},
    url = {https://doi.org/10.1093/nargab/lqaa026},
    note = {lqaa026},
    eprint = {https://academic.oup.com/nargab/article-pdf/2/2/lqaa026/34054524/lqaa026.pdf},
}



@Inbook{Sallet2019,
author="Sallet, Erika
and Gouzy, J{\'e}r{\^o}me
and Schiex, Thomas",
editor="Kollmar, Martin",
title="EuGene: An Automated Integrative Gene Finder for Eukaryotes and Prokaryotes",
bookTitle="Gene Prediction: Methods and Protocols ",
year="2019",
publisher="Springer New York",
address="New York, NY",
pages="97--120",
abstract="EuGene is an integrative gene finder applicable to both prokaryotic and eukaryotic genomes. EuGene annotated its first genome in 1999. Starting from genomic DNA sequences representing a complete genome, EuGene is able to predict the major transcript units in the genome from a variety of sources of information: statistical information, similarities with known transcripts and proteins, but also any GFF3 structured information supporting the presence or absence of specific types of elements. EuGene has been used to find genes in the plants Arabidopsis thaliana, Medicago truncatula, and Theobroma cacao; tomato, sunflower, and Rosa genomes; and in the nematode Meloidogyne incognita genome, among many others. The large fraction of plant in this list probably influenced EuGene development, especially in its capacities to withstand a genome with a large number of repeated regions and transposable elements.",
isbn="978-1-4939-9173-0",
doi="10.1007/978-1-4939-9173-0_6",
url="https://doi.org/10.1007/978-1-4939-9173-0_6"
}

@article{10.1093/bioinformatics/btv033,
    author = {Li, Dinghua and Liu, Chi-Man and Luo, Ruibang and Sadakane, Kunihiko and Lam, Tak-Wah},
    title = "{MEGAHIT: an ultra-fast single-node solution for large and complex metagenomics assembly via succinct de Bruijn graph}",
    journal = {Bioinformatics},
    volume = {31},
    number = {10},
    pages = {1674-1676},
    year = {2015},
    month = {01},
    abstract = "{Summary: MEGAHIT is a NGS de novo assembler for assembling large and complex metagenomics data in a time- and cost-efficient manner. It finished assembling a soil metagenomics dataset with 252 Gbps in 44.1 and 99.6 h on a single computing node with and without a graphics processing unit, respectively. MEGAHIT assembles the data as a whole, i.e. no pre-processing like partitioning and normalization was needed. When compared with previous methods on assembling the soil data, MEGAHIT generated a three-time larger assembly, with longer contig N50 and average contig length; furthermore, 55.8\\% of the reads were aligned to the assembly, giving a fourfold improvement.Availability and implementation: The source code of MEGAHIT is freely available at https://github.com/voutcn/megahit under GPLv3 license.Contact:rb@l3-bioinfo.com or twlam@cs.hku.hkSupplementary information: Supplementary data are available at Bioinformatics online.}",
    issn = {1367-4803},
    doi = {10.1093/bioinformatics/btv033},
    url = {https://doi.org/10.1093/bioinformatics/btv033},
    eprint = {https://academic.oup.com/bioinformatics/article-pdf/31/10/1674/17085710/btv033.pdf},
}



@article{10.1093/bioinformatics/bts174,
    author = {Peng, Yu and Leung, Henry C. M. and Yiu, S. M. and Chin, Francis Y. L.},
    title = "{IDBA-UD: a de novo assembler for single-cell and metagenomic sequencing data with highly uneven depth}",
    journal = {Bioinformatics},
    volume = {28},
    number = {11},
    pages = {1420-1428},
    year = {2012},
    month = {04},
    abstract = "{Motivation: Next-generation sequencing allows us to sequence reads from a microbial environment using single-cell sequencing or metagenomic sequencing technologies. However, both technologies suffer from the problem that sequencing depth of different regions of a genome or genomes from different species are highly uneven. Most existing genome assemblers usually have an assumption that sequencing depths are even. These assemblers fail to construct correct long contigs.Results: We introduce the IDBA-UD algorithm that is based on the de Bruijn graph approach for assembling reads from single-cell sequencing or metagenomic sequencing technologies with uneven sequencing depths. Several non-trivial techniques have been employed to tackle the problems. Instead of using a simple threshold, we use multiple depthrelative thresholds to remove erroneous k-mers in both low-depth and high-depth regions. The technique of local assembly with paired-end information is used to solve the branch problem of low-depth short repeat regions. To speed up the process, an error correction step is conducted to correct reads of high-depth regions that can be aligned to highconfident contigs. Comparison of the performances of IDBA-UD and existing assemblers (Velvet, Velvet-SC, SOAPdenovo and Meta-IDBA) for different datasets, shows that IDBA-UD can reconstruct longer contigs with higher accuracy.Availability: The IDBA-UD toolkit is available at our website http://www.cs.hku.hk/~alse/idba\_udContact:chin@cs.hku.hk}",
    issn = {1367-4803},
    doi = {10.1093/bioinformatics/bts174},
    url = {https://doi.org/10.1093/bioinformatics/bts174},
    eprint = {https://academic.oup.com/bioinformatics/article-pdf/28/11/1420/742285/bts174.pdf},
}



@Article{pmid10592173,
   Author="Kanehisa, M.  and Goto, S. ",
   Title="{{K}{E}{G}{G}: kyoto encyclopedia of genes and genomes}",
   Journal="Nucleic Acids Res",
   Year="2000",
   Volume="28",
   Number="1",
   Pages="27--30",
   Month="Jan",
   doi="10.1093/nar/28.1.27"
}
@Article{pmid31441146,
   Author="Kanehisa, M. ",
   Title="{{T}oward understanding the origin and evolution of cellular organisms}",
   Journal="Protein Sci",
   Year="2019",
   Volume="28",
   Number="11",
   Pages="1947--1951",
   Month="11",
   doi="10.1002/pro.3715"
}
@Article{pmid33125081,
   Author="Kanehisa, M.  and Furumichi, M.  and Sato, Y.  and Ishiguro-Watanabe, M.  and Tanabe, M. ",
   Title="{{K}{E}{G}{G}: integrating viruses and cellular organisms}",
   Journal="Nucleic Acids Res",
   Year="2021",
   Volume="49",
   Number="D1",
   Pages="D545-D551",
   Month="01",
   doi="10.1093/nar/gkaa970"
}

@misc{krakenmanual,
  Title="Kraken taxonomic sequence classification system: Operating Manual", 
  doi="10.1186/gb-2014-15-3-r46",
  url={https://ccb.jhu.edu/software/kraken/MANUAL.html}
} 

@misc{felix_krueger_2021_5127899,
  author       = {Felix Krueger and
                  Frankie James and
                  Phil Ewels and
                  Ebrahim Afyounian and
                  Benjamin Schuster-Boeckler},
  title        = {TrimGalore},
  month        = jul,
  year         = 2021,
  publisher    = {Zenodo},
  version      = {0.6.7},
  doi          = {10.5281/zenodo.5127899},
  url          = {https://doi.org/10.5281/zenodo.5127899}
}

@Article{pmid24695404,
   Author="Bolger, A. M.  and Lohse, M.  and Usadel, B. ",
   Title="{{T}rimmomatic: a flexible trimmer for {I}llumina sequence data}",
   Journal="Bioinformatics",
   Year="2014",
   Volume="30",
   Number="15",
   Pages="2114--2120",
   Month="Aug",
   doi="10.1093/bioinformatics/btu170"
}

@Article{pmid18287689,
   Author="Boutet, E.  and Lieberherr, D.  and Tognolli, M.  and Schneider, M.  and Bairoch, A. ",
   Title="{{U}ni{P}rot{K}{B}/{S}wiss-{P}rot}",
   Journal="Methods Mol Biol",
   Year="2007",
   Volume="406",
   Pages="89--112",
   doi="10.1007/978-1-59745-535-0_4"
}

@article{10.1093/bioinformatics/btr174,
    author = {Barnett, Derek W. and Garrison, Erik K. and Quinlan, Aaron R. and Strömberg, Michael P. and Marth, Gabor T.},
    title = "{BamTools: a C++ API and toolkit for analyzing and managing BAM files}",
    journal = {Bioinformatics},
    volume = {27},
    number = {12},
    pages = {1691-1692},
    year = {2011},
    month = {04},
    abstract = "{Motivation: Analysis of genomic sequencing data requires efficient, easy-to-use access to alignment results and flexible data management tools (e.g. filtering, merging, sorting, etc.). However, the enormous amount of data produced by current sequencing technologies is typically stored in compressed, binary formats that are not easily handled by the text-based parsers commonly used in bioinformatics research.Results: We introduce a software suite for programmers and end users that facilitates research analysis and data management using BAM files. BamTools provides both the first C++ API publicly available for BAM file support as well as a command-line toolkit.Availability: BamTools was written in C++, and is supported on Linux, Mac OSX and MS Windows. Source code and documentation are freely available at http://github.org/pezmaster31/bamtools.Contact:barnetde@bc.edu}",
    issn = {1367-4803},
    doi = {10.1093/bioinformatics/btr174},
    url = {https://doi.org/10.1093/bioinformatics/btr174},
    eprint = {https://academic.oup.com/bioinformatics/article-pdf/27/12/1691/709404/btr174.pdf},
}




@article{10.1093/bioinformatics/btp352,
    author = {Li, Heng and Handsaker, Bob and Wysoker, Alec and Fennell, Tim and Ruan, Jue and Homer, Nils and Marth, Gabor and Abecasis, Goncalo and Durbin, Richard and 1000 Genome Project Data Processing Subgroup},
    title = "{The Sequence Alignment/Map format and SAMtools}",
    journal = {Bioinformatics},
    volume = {25},
    number = {16},
    pages = {2078-2079},
    year = {2009},
    month = {06},
    abstract = "{Summary: The Sequence Alignment/Map (SAM) format is a generic alignment format for storing read alignments against reference sequences, supporting short and long reads (up to 128 Mbp) produced by different sequencing platforms. It is flexible in style, compact in size, efficient in random access and is the format in which alignments from the 1000 Genomes Project are released. SAMtools implements various utilities for post-processing alignments in the SAM format, such as indexing, variant caller and alignment viewer, and thus provides universal tools for processing read alignments.Availability:http://samtools.sourceforge.netContact:rd@sanger.ac.uk}",
    issn = {1367-4803},
    doi = {10.1093/bioinformatics/btp352},
    url = {https://doi.org/10.1093/bioinformatics/btp352},
    eprint = {https://academic.oup.com/bioinformatics/article-pdf/25/16/2078/531810/btp352.pdf},
}



@article{10.1093/bioinformatics/btw354,
    author = {Ewels, Philip and Magnusson, Måns and Lundin, Sverker and Käller, Max},
    title = "{{MultiQC: summarize analysis results for multiple tools and samples in a single report}}",
    journal = {Bioinformatics},
    volume = {32},
    number = {19},
    pages = {3047-3048},
    year = {2016},
    month = {06},
    abstract = "{Motivation: Fast and accurate quality control is essential for studies involving next-generation sequencing data. Whilst numerous tools exist to quantify QC metrics, there is no common approach to flexibly integrate these across tools and large sample sets. Assessing analysis results across an entire project can be time consuming and error prone; batch effects and outlier samples can easily be missed in the early stages of analysis.Results: We present MultiQC, a tool to create a single report visualising output from multiple tools across many samples, enabling global trends and biases to be quickly identified. MultiQC can plot data from many common bioinformatics tools and is built to allow easy extension and customization.Availability and implementation: MultiQC is available with an GNU GPLv3 license on GitHub, the Python Package Index and Bioconda. Documentation and example reports are available at http://multiqc.infoContact:phil.ewels@scilifelab.se}",
    issn = {1367-4803},
    doi = {10.1093/bioinformatics/btw354},
    url = {https://doi.org/10.1093/bioinformatics/btw354},
    eprint = {https://academic.oup.com/bioinformatics/article-pdf/32/19/3047/25072524/btw354.pdf},
}



@article{10.1093/bioinformatics/btab184,
    author = {Mirdita, M and Steinegger, M and Breitwieser, F and Söding, J and Levy Karin, E},
    title = "{Fast and sensitive taxonomic assignment to metagenomic contigs}",
    journal = {Bioinformatics},
    volume = {37},
    number = {18},
    pages = {3029-3031},
    year = {2021},
    month = {03},
    abstract = "{MMseqs2 taxonomy is a new tool to assign taxonomic labels to metagenomic contigs. It extracts all possible protein fragments from each contig, quickly retains those that can contribute to taxonomic annotation, assigns them with robust labels and determines the contig’s taxonomic identity by weighted voting. Its fragment extraction step is suitable for the analysis of all domains of life. MMseqs2 taxonomy is 2–18× faster than state-of-the-art tools and also contains new modules for creating and manipulating taxonomic reference databases as well as reporting and visualizing taxonomic assignments.MMseqs2 taxonomy is part of the MMseqs2 free open-source software package available for Linux, macOS and Windows at https://mmseqs.com.Supplementary data are available at Bioinformatics online.}",
    issn = {1367-4803},
    doi = {10.1093/bioinformatics/btab184},
    url = {https://doi.org/10.1093/bioinformatics/btab184},
    eprint = {https://academic.oup.com/bioinformatics/article-pdf/37/18/3029/40471478/btab184.pdf},
}


@article{keegan_glass_meyer_2016, 
    title={MG-RAST, a Metagenomics Service for Analysis of Microbial Community Structure and Function},
              DOI={10.1007/978-1-4939-3369-3_13},
              journal={Microbial Environmental Genomics (MEG)},
              author={Keegan, Kevin P. and Glass, Elizabeth M. and Meyer, Folker},
              year={2016},
              pages={207-233}
              }


@article{krakau_straub_gourle_gabernet_nahnsen_2022,
    author = {Krakau, Sabrina and Straub, Daniel and Gourlé, Hadrien and Gabernet, Gisela and Nahnsen, Sven},
    title = "{nf-core/mag: a best-practice pipeline for metagenome hybrid assembly and binning}",
    journal = {NAR Genomics and Bioinformatics},
    volume = {4},
    number = {1},
    year = {2022},
    month = {02},
    abstract = "{The analysis of shotgun metagenomic data provides valuable insights into microbial communities, while allowing resolution at individual genome level. In absence of complete reference genomes, this requires the reconstruction of metagenome assembled genomes (MAGs) from sequencing reads. We present the nf-core/mag pipeline for metagenome assembly, binning and taxonomic classification. It can optionally combine short and long reads to increase assembly continuity and utilize sample-wise group-information for co-assembly and genome binning. The pipeline is easy to install-all dependencies are provided within containers-portable and reproducible. It is written in Nextflow and developed as part of the nf-core initiative for best-practice pipeline development. All codes are hosted on GitHub under the nf-core organization https://github.com/nf-core/mag and released under the MIT license.}",
    issn = {2631-9268},
    doi = {10.1093/nargab/lqac007},
    url = {https://doi.org/10.1093/nargab/lqac007},
    note = {lqac007},
    eprint = {https://academic.oup.com/nargab/article-pdf/4/1/lqac007/42366621/lqac007.pdf},
}

@article{kieser_brown_zdobnov_trajkovski_mccue_2020,
    title={ATLAS: a Snakemake workflow for assembly, annotation, and genomic binning of metagenome sequence data},
    volume={21}, 
    DOI={10.1186/s12859-020-03585-4}, 
    number={1},
    journal={BMC Bioinformatics},
    author={Kieser, Silas and Brown, Joseph and Zdobnov, Evgeny M. and Trajkovski, Mirko and McCue, Lee Ann},
    year={2020}
}

@article{van_damme_hölzer_viehweger_müller_bongcam-rudloff_brandt_2021,
    title={Metagenomics workflow for hybrid assembly, differential coverage binning, metatranscriptomics and pathway analysis (MUFFIN)},
    volume={17},
     DOI={10.1371/journal.pcbi.1008716},
    number={2},
    journal={PLOS Computational Biology},
    author={Van Damme, Renaud and Hölzer, Martin and Viehweger, Adrian and Müller, Bettina and Bongcam-Rudloff, Erik and Brandt, Christian},
    year={2021},
    pages={e1008716}
}

@article{mölder_jablonski_letcher_hall_tomkins-tinch_sochat_forster_lee_twardziok_kanitz_et_al._2021,
    title={Sustainable data analysis with Snakemake},
    volume={10},
     DOI={10.12688/f1000research.29032.1},
    journal={F1000Research},
    author={Mölder, Felix and Jablonski, Kim Philipp and Letcher, Brice and Hall, Michael B. and Tomkins-Tinch, Christopher H. and Sochat, Vanessa and Forster, Jan and Lee, Soohyun and Twardziok, Sven O. and Kanitz, Alexander et al.},
    year={2021},
    pages={33}
}

@article{di_tommaso_chatzou_floden_barja_palumbo_notredame_2017,
    title={Nextflow enables reproducible computational workflows},
    volume={35},
    DOI={10.1038/nbt.3820},
    number={4},
    journal={Nature Biotechnology},
    author={Di Tommaso, Paolo and Chatzou, Maria and Floden, Evan W and Barja, Pablo Prieto and Palumbo, Emilio and Notredame, Cedric},
    year={2017},
    pages={316-319}
}

@article{kurtzer_sochat_bauer_2017,
    title={Singularity: Scientific containers for mobility of compute},
    volume={12},
    DOI={10.1371/journal.pone.0177459},
    number={5},
    journal={PLOS ONE},
    author={Kurtzer, Gregory M. and Sochat, Vanessa and Bauer, Michael W.},
    year={2017},
    pages={e0177459}
}

@article{mirdita_steinegger_breitwieser_söding_levy_karin_2021,
    title={Fast and sensitive taxonomic assignment to metagenomic contigs},
    volume={37},
    DOI={10.1093/bioinformatics/btab184},
    number={18},
    journal={Bioinformatics},
    author={Mirdita, M and Steinegger, M and Breitwieser, F and Söding, J and Levy Karin, E},
    year={2021},
    pages={3029-3031}
}

@misc{voss_van_der_auwera_gentry_2022, 
  title={Full-stack genomics pipelining with GATK4 + WDL + Cromwell},
    url={https://f1000research.com/slides/6-1381},
    doi="10.7490/f1000research.1114634.1",
    journal={F1000research.com},
    author={Voss, Kate and Van der Auwera, Geraldine and Gentry, Jeff},
    year={2022}
}

@article{aramaki_blanc-mathieu_endo_ohkubo_kanehisa_goto_ogata_2019,
    title={KofamKOALA: KEGG Ortholog assignment based on profile HMM and adaptive score threshold},
    volume={36},
     DOI={10.1093/bioinformatics/btz859},
    number={7},
     journal={Bioinformatics},
    author={Aramaki, Takuya and Blanc-Mathieu, Romain and Endo, Hisashi and Ohkubo, Koichi and Kanehisa, Minoru and Goto, Susumu and Ogata, Hiroyuki},
    year={2019},
    pages={2251-2252}
}

@article{uniprot_consortium_2018,
    title={UniProt: the universal protein knowledgebase},
    volume={46},
    DOI={10.1093/nar/gky092},
    number={5},
    journal={Nucleic Acids Research},
    author={UniProt Consortium, The},
    year={2018},
    pages={2699-2699}
}

@article{buchfink_reuter_drost_2021,
    title={Sensitive protein alignments at tree-of-life scale using DIAMOND},
    volume={18},
    DOI={10.1038/s41592-021-01101-x},
    number={4},
    journal={Nature Methods},
    author={Buchfink, Benjamin and Reuter, Klaus and Drost, Hajk-Georg},
    year={2021},
    pages={366-368}
}

@article{peng_leung_yiu_chin_2012,
    title={IDBA-UD: a de novo assembler for single-cell and metagenomic sequencing data with highly uneven depth},
    volume={28},
    DOI={10.1093/bioinformatics/bts174},
    number={11},
    journal={Bioinformatics},
    author={Peng, Y. and Leung, H. C. M. and Yiu, S. M. and Chin, F. Y. L.},
    year={2012},
    pages={1420-1428}
}

@article{hyatt_chen_locascio_land_larimer_hauser_2010,
    title={Prodigal: prokaryotic gene recognition and translation initiation site identification},
    volume={11},
    DOI={10.1186/1471-2105-11-119},
    number={1},
    journal={BMC Bioinformatics},
    author={Hyatt, Doug and Chen, Gwo-Liang and LoCascio, Philip F and Land, Miriam L and Larimer, Frank W and Hauser, Loren J},
    year={2010}
}

@article{hofmeyr_egan_georganas_copeland_riley_clum_eloe-fadrosh_roux_goltsman_buluç_et_al._2020,
    title={Terabase-scale metagenome coassembly with MetaHipMer},
    volume={10},
    DOI={10.1038/s41598-020-67416-5},
    number={1},
    journal={Scientific Reports},
    author={Hofmeyr, Steven and Egan, Rob and Georganas, Evangelos and Copeland, Alex C. and Riley, Robert and Clum, Alicia and Eloe-Fadrosh, Emiley and Roux, Simon and Goltsman, Eugene and Buluç, Aydın et al.},
    year={2020}
}


@article{hofmeyr2020,
    author = "Hofmeyr, Steven and Egan, Rob and Georganas, Evangelos and Copeland, Alex C. and Riley, Robert and Clum, Alicia and Eloe-Fadrosh, Emiley and Roux, Simon and Goltsman, Eugene and Buluç, Aydın and Rokhsar, Daniel and Oliker, Leonid and Yelick, Katherine",
    type = "Journal Article",
    title = "Terabase-scale metagenome coassembly with MetaHipMer",
    journal = "Scientific Reports",
    number = "1",
    doi = "10.1038/s41598-020-67416-5",
    volume = "10",
    pages = "10689",
    url = "https://doi.org/10.1038/s41598-020-67416-5",
    year = "2020",
    abstract = "Metagenome sequence datasets can contain terabytes of reads, too many to be coassembled together on a single shared-memory computer; consequently, they have only been assembled sample by sample (multiassembly) and combining the results is challenging. We can now perform coassembly of the largest datasets using MetaHipMer, a metagenome assembler designed to run on supercomputers and large clusters of compute nodes. We have reported on the implementation of MetaHipMer previously; in this paper we focus on analyzing the impact of very large coassembly. In particular, we show that coassembly recovers a larger genome fraction than multiassembly and enables the discovery of more complete genomes, with lower error rates, whereas multiassembly recovers more dominant strain variation. Being able to coassemble a large dataset does not preclude one from multiassembly; rather, having a fast, scalable metagenome assembler enables a user to more easily perform coassembly and multiassembly, and assemble both abundant, high strain variation genomes, and low-abundance, rare genomes. We present several assemblies of terabyte datasets that could never be coassembled before, demonstrating MetaHipMer’s scaling power. MetaHipMer is available for public use under an open source license and all datasets used in the paper are available for public download.",
    issn = "2045-2322",
    da = "2020/07/01"
}

@article{kang2019,
    author = "Kang, Dongwan D and Li, Feng and Kirton, Edward and Thomas, Ashleigh and Egan, Rob and An, Hong and Wang, Zhong",
    type = "Journal Article",
    title = "MetaBAT 2: an adaptive binning algorithm for robust and efficient genomereconstruction from metagenome assemblies.",
    journal = "PeerJ",
    date = "2019",
    volume = "7",
    pages = "e7359",
    keywords = "Clustering | Metagenome binning | Metagenomics",
    issn = "2167-8359 (Print); 2167-8359 (Electronic); 2167-8359 (Linking)",
    abstract = "We previously reported on MetaBAT, an automated metagenome binning software toolto reconstruct single genomes from microbial communities for subsequent analysesof uncultivated microbial species. MetaBAT has become one of the most popularbinning tools largely due to its computational efficiency and ease of use,especially in binning experiments with a large number of samples and a largeassembly. MetaBAT requires users to choose parameters to fine-tune itssensitivity and specificity. If those parameters are not chosen properly, binningaccuracy can suffer, especially on assemblies of poor quality. Here, we developedMetaBAT 2 to overcome this problem. MetaBAT 2 uses a new adaptive binningalgorithm to eliminate manual parameter tuning. We also performed extensivesoftware engineering optimization to increase both computational and memoryefficiency. Comparing MetaBAT 2 to alternative software tools on over 100 realworld metagenome assemblies shows superior accuracy and computing speed. Binninga typical metagenome assembly takes only a few minutes on a single commodityworkstation. We therefore recommend the community adopts MetaBAT 2 for theirmetagenome binning experiments. MetaBAT 2 is open source software and availableat https://bitbucket.org/berkeleylab/metabat.",
    year = "2019",
    doi = "10.7717/peerj.7359",
    pmid = "31388474",
    own = "NLM",
    stat = "PubMed-not-MEDLINE",
    lr = "20201001",
    lid = "10.7717/peerj.7359 [doi]; e7359",
    au = "Kang DD; Li F; Kirton E; Thomas A; Egan R; An H; Wang Z",
    ad = "Department of Energy, Joint Genome Institute, Walnut Creek, CA, USA.; School of Computer Science and Technology, University of Science and Technologyof China, Hefei, Anhui, China.; Department of Energy, Joint Genome Institute, Walnut Creek, CA, USA.; Department of Energy, Joint Genome Institute, Walnut Creek, CA, USA.; Department of Energy, Joint Genome Institute, Walnut Creek, CA, USA.; School of Computer Science and Technology, University of Science and Technologyof China, Hefei, Anhui, China.; Department of Energy, Joint Genome Institute, Walnut Creek, CA, USA.; Environmental Genomics and System Biology Division, Lawrence Berkeley NationalLaboratory, Berkeley, CA, USA.; School of Natural Sciences, University of California at Merced, Merced, CA, USA.",
    auid = "ORCID: 0000-0003-1974-1768; ORCID: 0000-0001-7422-5649; ORCID: 0000-0001-7080-7801; ORCID: 0000-0002-6307-0458",
    la = "eng",
    dep = "20190726",
    pl = "United States",
    ta = "PeerJ",
    jid = "101603425",
    pmc = "PMC6662567",
    oto = "NOTNLM",
    cois = "The authors declare that they have no competing interests.",
    edat = "2019/08/08 06:00",
    mhda = "2019/08/08 06:01",
    crdt = "2019/08/08 06:00",
    phst = "2019/02/06 00:00 [received]; 2019/06/26 00:00 [accepted]; 2019/08/08 06:00 [entrez]; 2019/08/08 06:00 [pubmed]; 2019/08/08 06:01 [medline]",
    pst = "epublish",
    so = "PeerJ. 2019 Jul 26;7:e7359. doi: 10.7717/peerj.7359. eCollection 2019.",
    aid = "7359 [pii]"
}
@article {Gonzalez-Tortuero2021.12.11.472104,
	author = {Gonz{\'a}lez-Tortuero, Enrique and Krishnamurthi, Revathy and Allison, Heather E. and Goodhead, Ian B. and James, Chlo{\"e} E.},
	title = {Comparative analysis of gene prediction tools for viral genome annotation},
	elocation-id = {2021.12.11.472104},
	year = {2021},
	doi = {10.1101/2021.12.11.472104},
	publisher = {Cold Spring Harbor Laboratory},
	abstract = {The number of newly available viral genomes and metagenomes has increased exponentially since the development of high throughput sequencing platforms and genome analysis tools. Bioinformatic annotation pipelines are largely based on open reading frame (ORF) calling software, which identifies genes independently of the sequence taxonomical background. Although ORF-calling programs provide a rapid genome annotation, they can misidentify ORFs and start codons; errors that might be perpetuated and propagated over time. This study evaluated the performance of multiple ORF-calling programs for viral genome annotation against the complete RefSeq viral database. Programs outputs varied when considering the viral nucleic acid type versus the viral host. According to the number of ORFs, Prodigal and Metaprodigal were the most accurate programs for DNA viruses, while FragGeneScan and Prodigal generated the most accurate outputs for RNA viruses. Similarly, Prodigal outperformed the benchmark for viruses infecting prokaryotes, and GLIMMER and GeneMarkS produced the most accurate annotations for viruses infecting eukaryotes. When the coordinates of the ORFs were considered, Prodigal scored high for all scenarios except for RNA viruses, where GeneMarkS generated the most reliable results. Overall, the quality of the coordinates predicted for RNA viruses was poorer than for DNA viruses, suggesting the need for improved ORF-calling programs to deal with RNA viruses. Moreover, none of the ORF-calling programs reached 90\% accuracy for annotation of DNA viruses. Any automatic annotation can still be improved by manual curation, especially when the presence of ORFs is validated with wet-lab experiments. However, our evaluation of the current ORF-calling programs is expected to be useful for the improvement of viral genome annotation pipelines and highlights the need for more expression data to improve the rigor of reference genomes.Competing Interest StatementThe authors have declared no competing interest.},
	URL = {https://www.biorxiv.org/content/early/2021/12/13/2021.12.11.472104},
	eprint = {https://www.biorxiv.org/content/early/2021/12/13/2021.12.11.472104.full.pdf},
	journal = {bioRxiv}
}

@article{10.1093/bioinformatics/btv383,
    author = {Wick, Ryan R. and Schultz, Mark B. and Zobel, Justin and Holt, Kathryn E.},
    title = "{Bandage: interactive visualization of de novo genome assemblies}",
    journal = {Bioinformatics},
    volume = {31},
    number = {20},
    pages = {3350-3352},
    year = {2015},
    month = {06},
    abstract = "{Summary: Although de novo assembly graphs contain assembled contigs (nodes), the connections between those contigs (edges) are difficult for users to access. Bandage (a Bioinformatics Application for Navigating De novo Assembly Graphs Easily) is a tool for visualizing assembly graphs with connections. Users can zoom in to specific areas of the graph and interact with it by moving nodes, adding labels, changing colors and extracting sequences. BLAST searches can be performed within the Bandage graphical user interface and the hits are displayed as highlights in the graph. By displaying connections between contigs, Bandage presents new possibilities for analyzing de novo assemblies that are not possible through investigation of contigs alone.Availability and implementation: Source code and binaries are freely available at https://github.com/rrwick/Bandage. Bandage is implemented in C++ and supported on Linux, OS X and Windows. A full feature list and screenshots are available at http://rrwick.github.io/Bandage.Contact:rrwick@gmail.comSupplementary information:Supplementary data are available at Bioinformatics online.}",
    issn = {1367-4803},
    doi = {10.1093/bioinformatics/btv383},
    url = {https://doi.org/10.1093/bioinformatics/btv383},
    eprint = {https://academic.oup.com/bioinformatics/article-pdf/31/20/3350/17088082/btv383.pdf},
}



@InProceedings{10.1007/978-3-031-04749-7_5,
author="Mallawaarachchi, Vijini
and Lin, Yu",
editor="Pe'er, Itsik",
title="MetaCoAG: Binning Metagenomic Contigs via Composition, Coverage and Assembly Graphs",
booktitle="Research in Computational Molecular Biology",
year="2022",
publisher="Springer International Publishing",
address="Cham",
pages="70--85",
abstract="Metagenomics has allowed us to obtain various genetic material from different species and gain valuable insights into microbial communities. Binning plays an important role in the early stages of metagenomic analysis pipelines. A typical pipeline in metagenomics binning is to assemble short reads into longer contigs and then bin into groups representing different species in the metagenomic sample. While existing binning tools bin metagenomic contigs, they do not make use of the assembly graphs that produce such assemblies. Here we propose MetaCoAG, a tool that utilizes assembly graphs with the composition and coverage information to bin metagenomic contigs. MetaCoAG uses single-copy marker genes to estimate the number of initial bins, assigns contigs into bins iteratively and adjusts the number of bins dynamically throughout the binning process. Experimental results on simulated and real datasets demonstrate that MetaCoAG significantly outperforms state-of-the-art binning tools, producing similar or more high-quality bins than the second-best tool. To the best of our knowledge, MetaCoAG is the first stand-alone contig-binning tool to make direct use of the assembly graph information.",
isbn="978-3-031-04749-7"
}

